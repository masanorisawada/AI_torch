{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PyTorchで画像分類（補足済み）\n",
    "## コピペするのではなく、このファイルを見ながら、元の「PyTorch_MLP_MNIST.ipynb」を仕上げていきましょう\n",
    "\n",
    "- MLPによるMNIST（手書き文字）の分類\n",
    "- ミニバッチ学習\n",
    "- （ローカルPC上でCPU or GPU） or AWSクラウドGPU の利用\n",
    "\n",
    "処理の流れ\n",
    "\n",
    "1. デバイス設定\n",
    "1. データセットの用意\n",
    "1. 前処理\n",
    "1. 入力データのチェック\n",
    "1. ネットワークモデルの定義\n",
    "1. 損失関数、最適化関数の定義\n",
    "1. モデルの学習\n",
    "1. 検証\n",
    "\n",
    "補足：学習済みモデルの読書\n",
    "\n",
    "1. 学習済みモデルを保存\n",
    "1. 学習済みモデルを読込"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch # Tensorを作成・操作するための機能、GPUの使用も設定\n",
    "import torch.nn as nn # NNを構築する部品を提供\n",
    "import torch.optim as optim # SGD, Adamなどの最適化関数や学習率を設定\n",
    "from torchvision import datasets, transforms # 画像データの拡張やリサイズ、正規化などの前処理機能を提供\n",
    "from torch.utils.data import DataLoader # ミニバッチ用、例えばDatasetから指定した数の画像と正解ラベルを取り出す\n",
    "\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns # matplotlibの機能補助\n",
    "\n",
    "import time # 処理時間計測用"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. モデルの学習に用いるデバイスの設定"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0.モデルの学習に用いるデバイスの設定"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2＆3. データセットの用意しながら前処理も\n",
    "### MNIST\n",
    "- 60,000枚の訓練データ・・・モデルの学習に用いる\n",
    "- 10,000枚のテストデータ（正確には検証データ）・・・学習済みモデルの評価に用いる（モデルの学習には用いない）\n",
    "\n",
    "### それぞれのデータを格納する変数\n",
    "- train_dataset：訓練データ\n",
    "- test_dataset：テストデータ（正確には検証データ）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5ee0fec823524036abb950974919d3bf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/cifar-10-python.tar.gz to ./data\n"
     ]
    }
   ],
   "source": [
    "# 訓練データの用意\n",
    "train_dataset = datasets.CIFAR10(\n",
    "    root=\"./data\", \n",
    "    train=True, download=True, # trainが Trueになっていること要チェック\n",
    "    transform=transforms.ToTensor()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "# テストデータ（検証データ）の用意\n",
    "test_dataset = datasets.CIFAR10(\n",
    "    root='./data',\n",
    "    train=False, download=True,# trainが Falseになっていること要チェック\n",
    "    transform=transforms.ToTensor()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "学習に使用するデバイス： cuda\n"
     ]
    }
   ],
   "source": [
    "# もしGPUが利用可能なら cuda が入る\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "# 上の1行（三項演算子）は下と同じ処理\n",
    "# if torch.cuda.is_available():\n",
    "#   device = 'cuda'\n",
    "# else:\n",
    "#   device = 'cpu'   \n",
    "\n",
    "print('学習に使用するデバイス：',device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. データセットの用意\n",
    "### 変数名：train_dataset・・・訓練データ：モデルの学習に用いる\n",
    "### 変数名：test_dataset・・・テストデータ（正確には検証データ）：モデルの学習に用いない、学習済みモデルの評価に用いる"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# そもそも transform とはどのような処理が施された結果なのか、上の2つのセルを分解すると以下のとおり\n",
    "\n",
    "# transform = transforms.Compose([\n",
    "#     PyTorchのネットワークモデルに読み込ませるための変換処理\n",
    "#     1. 画像をTensorに変換\n",
    "#     2. 画像データ配列の軸を入れ替える　Channel Last → Channel First  つまり (H, W, C) → (C, H, W)  ※ Kerasは逆\n",
    "#     3. 0-255の範囲 → 0.0-1.0 に変換\n",
    "#     　　　　↓\n",
    "#     transforms.ToTensor() \n",
    "# ])\n",
    "\n",
    "# train_dataset = datasets.MNIST(\n",
    "#     root=\"./data\", \n",
    "#     train=True, download=True,\n",
    "#     transform=transform　# 上で定義した transform　を代入\n",
    "# )\n",
    "\n",
    "# test_dataset = datasets.MNIST(\n",
    "#     root=\"./data\", \n",
    "#     train=False, download=True,\n",
    "#     transform=transform　# 上で定義した transform　を代入\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 前処理の続き：ミニバッチのサイズ(num_batches）を決める\n",
    "\n",
    "### ミニバッチ学習：例えば 60,000 枚を 100 枚ずつに分けて学習する　※ちなみに60,000 枚を一度に学習することをバッチ学習という\n",
    "\n",
    "### ミニバッチ学習用データを格納する変数\n",
    "- train_dataloader：訓練データ（100枚 x 600セット）\n",
    "- test_dataloader：テストデータ（100枚 x 100セット）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_batches = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. 入力データのチェック\n",
    "### Tensorの形状を確認\n",
    "### 画像の確認\n",
    "### 画像データと正解ラベルの簡単な照合"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "訓練データの概要： Dataset CIFAR10\n",
      "    Number of datapoints: 50000\n",
      "    Root location: ./data\n",
      "    Split: Train\n",
      "    StandardTransform\n",
      "Transform: ToTensor()\n",
      "ミニバッチサイズ： 100\n"
     ]
    }
   ],
   "source": [
    "# 100枚ごとに画像と教師データをセットにして train_dataloaderに入れる\n",
    "train_dataloader = DataLoader(\n",
    "    train_dataset, \n",
    "    batch_size=num_batches, \n",
    "    shuffle=True\n",
    ")\n",
    "print('訓練データの概要：',train_dataloader.dataset)\n",
    "print('ミニバッチサイズ：',train_dataloader.batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "訓練データの概要： Dataset CIFAR10\n",
      "    Number of datapoints: 10000\n",
      "    Root location: ./data\n",
      "    Split: Test\n",
      "    StandardTransform\n",
      "Transform: ToTensor()\n",
      "ミニバッチサイズ： 100\n"
     ]
    }
   ],
   "source": [
    "# 100枚ごとに画像と教師データをセットにして test_dataloaderに入れる\n",
    "test_dataloader = DataLoader(\n",
    "    test_dataset, \n",
    "    batch_size=num_batches, \n",
    "    shuffle=True\n",
    ")\n",
    "print('訓練データの概要：',test_dataloader.dataset)\n",
    "print('ミニバッチサイズ：',test_dataloader.batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([100, 3, 32, 32])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# iter()はリストやタプルなど複数の要素を持つデータに対して、要素を最初から順番に取り出すことができる。\n",
    "# 要素を取り出すときにはnext()を使う\n",
    "\n",
    "train_iter = iter(train_dataloader)\n",
    "imgs, labels = train_iter.next()\n",
    "imgs.size() # サイズ・順番を確認　 # バッチサイズ、カラーチャンネル、高さ、幅　＝ 100、1、28、28　"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([7, 2, 9, 1, 4, 6, 4, 7, 0, 4, 6, 5, 6, 3, 6, 4, 9, 8, 2, 2, 9, 2, 3, 5,\n",
       "        6, 8, 0, 0, 5, 8, 6, 7, 3, 3, 3, 4, 2, 1, 8, 6, 2, 8, 5, 7, 5, 1, 4, 8,\n",
       "        0, 2, 2, 2, 7, 7, 6, 8, 3, 2, 8, 7, 3, 5, 3, 4, 1, 7, 3, 9, 7, 2, 1, 1,\n",
       "        3, 1, 4, 1, 4, 5, 6, 0, 7, 6, 2, 2, 5, 4, 8, 1, 7, 2, 5, 7, 6, 7, 1, 1,\n",
       "        5, 4, 7, 1])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels # 正解ラベルの確認"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f34edca7da0>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.heatmap(imgs[0].permute(1,2,0).numpy()[:,:,0]) # 画像確認\n",
    "# permute 画像データ配列の軸の順番を入れ替える 0,1,2 → 1,2,0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(7)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels[0] # 0番目のデータについて上の画像と下の数値が一致していることを確認"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. ネットワークモデルの定義"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "\n",
    "    # モデルの初期化方法を定義\n",
    "    def __init__(self):\n",
    "        super().__init__() # 親クラスの初期化\n",
    "        self.Peso_classifier = nn.Sequential( # 名付けは自由 Peso_claasifier # Sequentialで処理をまとめて記述\n",
    "            # 中間層（隠れ層）\n",
    "            # nn.Linerは全結合層\n",
    "            # 第1層 入力数に注意（カラーチャンネル数 x 画像の高さ x 画像の幅）\n",
    "#             nn.Linear(1 * 28 * 28, 400), # in_features= 1 * 28 * 28, out_features= 400\n",
    "            nn.Linear(3 * 32 * 32, 400),\n",
    "            nn.Dropout2d(0, 2),\n",
    "            nn.ReLU(inplace=True), # ReLUの実行結果で元の値を置き換える　メモリ節約\n",
    "            \n",
    "            # 第2層\n",
    "            nn.Linear(400, 200), # in_features= 400, out_features= 200\n",
    "            nn.ReLU(inplace=True),\n",
    "\n",
    "            # 第3層\n",
    "            nn.Linear(200, 100),\n",
    "            nn.ReLU(inplace=True),\n",
    "\n",
    "            # 第4層\n",
    "            nn.Linear(100, 10) # # in_features= 100, out_features= 10  ←　0 - 9 の10クラスで分類するため\n",
    "        )\n",
    "\n",
    "    # 順伝播の処理方法と定義\n",
    "    def forward(self, x):\n",
    "        output = self.Peso_classifier(x) # ←　上で付けた名前を間違えないように\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (Peso_classifier): Sequential(\n",
       "    (0): Linear(in_features=3072, out_features=400, bias=True)\n",
       "    (1): Dropout2d(p=0, inplace=2)\n",
       "    (2): ReLU(inplace=True)\n",
       "    (3): Linear(in_features=400, out_features=200, bias=True)\n",
       "    (4): ReLU(inplace=True)\n",
       "    (5): Linear(in_features=200, out_features=100, bias=True)\n",
       "    (6): ReLU(inplace=True)\n",
       "    (7): Linear(in_features=100, out_features=10, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = MLP() # ネットワークモデルのインスタンス化（実際使えるようにする手続き）\n",
    "model.to(device) # ネットワークモデルをデバイス CPU or GPU で使用するための設定"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. 損失関数、最適化関数の定義"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss() # 損失関数の定義　多クラス分類なのでクロスエントロピー\n",
    "# optimizer = optim.Adam(model.parameters(), lr=0.001) # 最適化関数を定義、lr = 学習率 詳しくは公式ドキュメント参照　https://pytorch.org/docs/stable/optim.html?highlight=adagrad#torch.optim.Adam\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.001)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. モデルの学習"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0, loss: 2.3029121475219725\n",
      "epoch: 1, loss: 2.2995783953666686\n",
      "epoch: 2, loss: 2.2959736194610594\n",
      "epoch: 3, loss: 2.292089169025421\n",
      "epoch: 4, loss: 2.287793831348419\n",
      "epoch: 5, loss: 2.2827953691482543\n",
      "epoch: 6, loss: 2.276719856262207\n",
      "epoch: 7, loss: 2.2690961985588074\n",
      "epoch: 8, loss: 2.2594150438308716\n",
      "epoch: 9, loss: 2.247084102630615\n",
      "epoch: 10, loss: 2.2314562363624573\n",
      "epoch: 11, loss: 2.2117703943252565\n",
      "epoch: 12, loss: 2.1882536449432375\n",
      "epoch: 13, loss: 2.1620075216293335\n",
      "epoch: 14, loss: 2.1352027316093443\n",
      "epoch: 15, loss: 2.1102829115390778\n",
      "epoch: 16, loss: 2.088636036157608\n",
      "epoch: 17, loss: 2.07003254199028\n",
      "epoch: 18, loss: 2.053889605283737\n",
      "epoch: 19, loss: 2.039501362800598\n",
      "epoch: 20, loss: 2.0265723805427553\n",
      "epoch: 21, loss: 2.014821240901947\n",
      "epoch: 22, loss: 2.0038656408786775\n",
      "epoch: 23, loss: 1.9936354410648347\n",
      "epoch: 24, loss: 1.9841295523643494\n",
      "epoch: 25, loss: 1.9748576035499572\n",
      "epoch: 26, loss: 1.965978982925415\n",
      "epoch: 27, loss: 1.9574732179641723\n",
      "epoch: 28, loss: 1.949260409116745\n",
      "epoch: 29, loss: 1.9414761881828309\n",
      "epoch: 30, loss: 1.9340194933414459\n",
      "epoch: 31, loss: 1.9269568157196044\n",
      "epoch: 32, loss: 1.9202496500015258\n",
      "epoch: 33, loss: 1.9139478797912597\n",
      "epoch: 34, loss: 1.9078927702903747\n",
      "epoch: 35, loss: 1.9021234321594238\n",
      "epoch: 36, loss: 1.896825716972351\n",
      "epoch: 37, loss: 1.8915580871105193\n",
      "epoch: 38, loss: 1.8863165509700774\n",
      "epoch: 39, loss: 1.881454339981079\n",
      "epoch: 40, loss: 1.8765885832309723\n",
      "epoch: 41, loss: 1.8718429682254791\n",
      "epoch: 42, loss: 1.8669556517601014\n",
      "epoch: 43, loss: 1.8620655908584596\n",
      "epoch: 44, loss: 1.8574613313674926\n",
      "epoch: 45, loss: 1.8529145288467408\n",
      "epoch: 46, loss: 1.8481391859054566\n",
      "epoch: 47, loss: 1.8436005430221558\n",
      "epoch: 48, loss: 1.8389145004749299\n",
      "epoch: 49, loss: 1.8341729063987733\n",
      "epoch: 50, loss: 1.8295482790470123\n",
      "epoch: 51, loss: 1.8250459296703339\n",
      "epoch: 52, loss: 1.8205586230754853\n",
      "epoch: 53, loss: 1.8159872608184815\n",
      "epoch: 54, loss: 1.8116189832687377\n",
      "epoch: 55, loss: 1.807201539039612\n",
      "epoch: 56, loss: 1.802476080417633\n",
      "epoch: 57, loss: 1.798082326412201\n",
      "epoch: 58, loss: 1.7937616477012635\n",
      "epoch: 59, loss: 1.789241199493408\n",
      "epoch: 60, loss: 1.7849032990932465\n",
      "epoch: 61, loss: 1.7804253072738647\n",
      "epoch: 62, loss: 1.776424616575241\n",
      "epoch: 63, loss: 1.7718646936416627\n",
      "epoch: 64, loss: 1.767626391172409\n",
      "epoch: 65, loss: 1.7633372147083282\n",
      "epoch: 66, loss: 1.7592555694580079\n",
      "epoch: 67, loss: 1.7549296202659608\n",
      "epoch: 68, loss: 1.7508380222320556\n",
      "epoch: 69, loss: 1.7469230649471283\n",
      "epoch: 70, loss: 1.7427346658706666\n",
      "epoch: 71, loss: 1.7388137164115907\n",
      "epoch: 72, loss: 1.7348437440395355\n",
      "epoch: 73, loss: 1.730853497505188\n",
      "epoch: 74, loss: 1.7268716797828674\n",
      "epoch: 75, loss: 1.723219701051712\n",
      "epoch: 76, loss: 1.7195543367862702\n",
      "epoch: 77, loss: 1.7155549700260162\n",
      "epoch: 78, loss: 1.712325386285782\n",
      "epoch: 79, loss: 1.7081758139133454\n",
      "epoch: 80, loss: 1.7048364946842194\n",
      "epoch: 81, loss: 1.7013427040576934\n",
      "epoch: 82, loss: 1.6978012852668762\n",
      "epoch: 83, loss: 1.6946418590545653\n",
      "epoch: 84, loss: 1.6910354475975036\n",
      "epoch: 85, loss: 1.6876356194019317\n",
      "epoch: 86, loss: 1.684183652162552\n",
      "epoch: 87, loss: 1.681170000076294\n",
      "epoch: 88, loss: 1.6776886641979218\n",
      "epoch: 89, loss: 1.674655558824539\n",
      "epoch: 90, loss: 1.671469078063965\n",
      "epoch: 91, loss: 1.6681823737621306\n",
      "epoch: 92, loss: 1.6647331211566925\n",
      "epoch: 93, loss: 1.662014443397522\n",
      "epoch: 94, loss: 1.658605865240097\n",
      "epoch: 95, loss: 1.6552769074440001\n",
      "epoch: 96, loss: 1.6522324500083923\n",
      "epoch: 97, loss: 1.6492285597324372\n",
      "epoch: 98, loss: 1.6461857492923737\n",
      "epoch: 99, loss: 1.643021096467972\n",
      "epoch: 100, loss: 1.6401072971820831\n",
      "epoch: 101, loss: 1.6364143850803374\n",
      "epoch: 102, loss: 1.6338611660003661\n",
      "epoch: 103, loss: 1.6308261966705322\n",
      "epoch: 104, loss: 1.6275505533218384\n",
      "epoch: 105, loss: 1.624568914413452\n",
      "epoch: 106, loss: 1.6217140171527862\n",
      "epoch: 107, loss: 1.6183061170578004\n",
      "epoch: 108, loss: 1.6152865283489228\n",
      "epoch: 109, loss: 1.6122760877609252\n",
      "epoch: 110, loss: 1.609050808429718\n",
      "epoch: 111, loss: 1.6062129893302917\n",
      "epoch: 112, loss: 1.6037367525100708\n",
      "epoch: 113, loss: 1.599730920791626\n",
      "epoch: 114, loss: 1.5966066634654998\n",
      "epoch: 115, loss: 1.5933362293243407\n",
      "epoch: 116, loss: 1.5907184095382692\n",
      "epoch: 117, loss: 1.5875179357528686\n",
      "epoch: 118, loss: 1.5843069095611573\n",
      "epoch: 119, loss: 1.5814786367416382\n",
      "epoch: 120, loss: 1.578212351322174\n",
      "epoch: 121, loss: 1.5752289509773254\n",
      "epoch: 122, loss: 1.5718547978401185\n",
      "epoch: 123, loss: 1.5686973226070404\n",
      "epoch: 124, loss: 1.565603440284729\n",
      "epoch: 125, loss: 1.5629291596412658\n",
      "epoch: 126, loss: 1.559472093820572\n",
      "epoch: 127, loss: 1.5557570960521698\n",
      "epoch: 128, loss: 1.5530655925273895\n",
      "epoch: 129, loss: 1.5499019730091095\n",
      "epoch: 130, loss: 1.5463290317058562\n",
      "epoch: 131, loss: 1.5437908074855804\n",
      "epoch: 132, loss: 1.5402660465240479\n",
      "epoch: 133, loss: 1.5373010292053222\n",
      "epoch: 134, loss: 1.5339332535266876\n",
      "epoch: 135, loss: 1.5306963193416596\n",
      "epoch: 136, loss: 1.5277170555591584\n",
      "epoch: 137, loss: 1.5246893961429595\n",
      "epoch: 138, loss: 1.5211559174060822\n",
      "epoch: 139, loss: 1.5185906715393067\n",
      "epoch: 140, loss: 1.5149560329914094\n",
      "epoch: 141, loss: 1.5122896912097932\n",
      "epoch: 142, loss: 1.5095292842388153\n",
      "epoch: 143, loss: 1.5063002061843873\n",
      "epoch: 144, loss: 1.5034742188453674\n",
      "epoch: 145, loss: 1.500468667268753\n",
      "epoch: 146, loss: 1.4978700301647185\n",
      "epoch: 147, loss: 1.4954795925617217\n",
      "epoch: 148, loss: 1.4922958035469056\n",
      "epoch: 149, loss: 1.489456156730652\n",
      "epoch: 150, loss: 1.4863969008922577\n",
      "epoch: 151, loss: 1.4842359306812287\n",
      "epoch: 152, loss: 1.4812027881145478\n",
      "epoch: 153, loss: 1.47838826918602\n",
      "epoch: 154, loss: 1.4753910839557647\n",
      "epoch: 155, loss: 1.4729828400611877\n",
      "epoch: 156, loss: 1.4698614251613618\n",
      "epoch: 157, loss: 1.46793922829628\n",
      "epoch: 158, loss: 1.4649213480949401\n",
      "epoch: 159, loss: 1.4624231595993042\n",
      "epoch: 160, loss: 1.4607124948501586\n",
      "epoch: 161, loss: 1.4574322955608368\n",
      "epoch: 162, loss: 1.4549534492492675\n",
      "epoch: 163, loss: 1.45282643532753\n",
      "epoch: 164, loss: 1.4500387134552002\n",
      "epoch: 165, loss: 1.447926609992981\n",
      "epoch: 166, loss: 1.4454003422260284\n",
      "epoch: 167, loss: 1.4422034974098206\n",
      "epoch: 168, loss: 1.4402534556388855\n",
      "epoch: 169, loss: 1.4379749140739442\n",
      "epoch: 170, loss: 1.4355024635791778\n",
      "epoch: 171, loss: 1.4328824241161346\n",
      "epoch: 172, loss: 1.4309949243068696\n",
      "epoch: 173, loss: 1.4285006008148193\n",
      "epoch: 174, loss: 1.4265538647174836\n",
      "epoch: 175, loss: 1.422772734642029\n",
      "epoch: 176, loss: 1.4216390745639802\n",
      "epoch: 177, loss: 1.4177067034244537\n",
      "epoch: 178, loss: 1.4162894492149354\n",
      "epoch: 179, loss: 1.414384288072586\n",
      "epoch: 180, loss: 1.4113629803657533\n",
      "epoch: 181, loss: 1.4090223882198334\n",
      "epoch: 182, loss: 1.4077562479972838\n",
      "epoch: 183, loss: 1.4055840351581574\n",
      "epoch: 184, loss: 1.4031735289096832\n",
      "epoch: 185, loss: 1.4002985424995422\n",
      "epoch: 186, loss: 1.397898924589157\n",
      "epoch: 187, loss: 1.3957647132873534\n",
      "epoch: 188, loss: 1.3939065630435943\n",
      "epoch: 189, loss: 1.3908132512569427\n",
      "epoch: 190, loss: 1.388541559457779\n",
      "epoch: 191, loss: 1.3868632349967958\n",
      "epoch: 192, loss: 1.385334780216217\n",
      "epoch: 193, loss: 1.3831360828876496\n",
      "epoch: 194, loss: 1.38025079536438\n",
      "epoch: 195, loss: 1.378843959569931\n",
      "epoch: 196, loss: 1.3750444419384003\n",
      "epoch: 197, loss: 1.3729457716941833\n",
      "epoch: 198, loss: 1.371329241514206\n",
      "epoch: 199, loss: 1.368469188451767\n",
      "epoch: 200, loss: 1.3656694266796112\n",
      "epoch: 201, loss: 1.3646848073005677\n",
      "epoch: 202, loss: 1.3613044428825378\n",
      "epoch: 203, loss: 1.3601978371143342\n",
      "epoch: 204, loss: 1.3584121444225312\n",
      "epoch: 205, loss: 1.3548178281784058\n",
      "epoch: 206, loss: 1.3529376227855683\n",
      "epoch: 207, loss: 1.3500292241573333\n",
      "epoch: 208, loss: 1.3487242469787597\n",
      "epoch: 209, loss: 1.3459658935070038\n",
      "epoch: 210, loss: 1.3431233451366424\n",
      "epoch: 211, loss: 1.3398002650737761\n",
      "epoch: 212, loss: 1.3392809298038482\n",
      "epoch: 213, loss: 1.3377794790267945\n",
      "epoch: 214, loss: 1.3354372410774231\n",
      "epoch: 215, loss: 1.332265843153\n",
      "epoch: 216, loss: 1.3300228933095932\n",
      "epoch: 217, loss: 1.327612719297409\n",
      "epoch: 218, loss: 1.3263934276103972\n",
      "epoch: 219, loss: 1.3245426952838897\n",
      "epoch: 220, loss: 1.3216964333057404\n",
      "epoch: 221, loss: 1.3180314931869508\n",
      "epoch: 222, loss: 1.3165969800949098\n",
      "epoch: 223, loss: 1.314614240884781\n",
      "epoch: 224, loss: 1.3123287663459777\n",
      "epoch: 225, loss: 1.310674512386322\n",
      "epoch: 226, loss: 1.3087787899971008\n",
      "epoch: 227, loss: 1.306619327545166\n",
      "epoch: 228, loss: 1.3052905232906342\n",
      "epoch: 229, loss: 1.3020632424354552\n",
      "epoch: 230, loss: 1.3012006597518921\n",
      "epoch: 231, loss: 1.2970151016712188\n",
      "epoch: 232, loss: 1.2964710731506348\n",
      "epoch: 233, loss: 1.2927844457626343\n",
      "epoch: 234, loss: 1.2922826461791992\n",
      "epoch: 235, loss: 1.288866463303566\n",
      "epoch: 236, loss: 1.2892725205421447\n",
      "epoch: 237, loss: 1.2838730043172837\n",
      "epoch: 238, loss: 1.2818116431236266\n",
      "epoch: 239, loss: 1.2804928101301194\n",
      "epoch: 240, loss: 1.2769796116352081\n",
      "epoch: 241, loss: 1.2756438853740693\n",
      "epoch: 242, loss: 1.2739002342224122\n",
      "epoch: 243, loss: 1.2716743322610855\n",
      "epoch: 244, loss: 1.2702621417045594\n",
      "epoch: 245, loss: 1.266735740661621\n",
      "epoch: 246, loss: 1.266204890847206\n",
      "epoch: 247, loss: 1.2635469672679902\n",
      "epoch: 248, loss: 1.2630975657701493\n",
      "epoch: 249, loss: 1.2583937848806381\n",
      "epoch: 250, loss: 1.2576927572488785\n",
      "epoch: 251, loss: 1.2559232689142228\n",
      "epoch: 252, loss: 1.2536260441541671\n",
      "epoch: 253, loss: 1.2512604591846466\n",
      "epoch: 254, loss: 1.2490875389575957\n",
      "epoch: 255, loss: 1.246034351706505\n",
      "epoch: 256, loss: 1.2447432440519333\n",
      "epoch: 257, loss: 1.2447797915935517\n",
      "epoch: 258, loss: 1.2405847988128662\n",
      "epoch: 259, loss: 1.2396032832860946\n",
      "epoch: 260, loss: 1.237935843706131\n",
      "epoch: 261, loss: 1.234842835187912\n",
      "epoch: 262, loss: 1.2335219402313233\n",
      "epoch: 263, loss: 1.2291796352863311\n",
      "epoch: 264, loss: 1.228615611553192\n",
      "epoch: 265, loss: 1.225848676919937\n",
      "epoch: 266, loss: 1.2255944145917892\n",
      "epoch: 267, loss: 1.2250014760494232\n",
      "epoch: 268, loss: 1.220311970949173\n",
      "epoch: 269, loss: 1.218519456744194\n",
      "epoch: 270, loss: 1.2176658329963683\n",
      "epoch: 271, loss: 1.21274784386158\n",
      "epoch: 272, loss: 1.212078283548355\n",
      "epoch: 273, loss: 1.2120311512947082\n",
      "epoch: 274, loss: 1.2073281546831132\n",
      "epoch: 275, loss: 1.2067214860916138\n",
      "epoch: 276, loss: 1.204736196398735\n",
      "epoch: 277, loss: 1.2013393311500549\n",
      "epoch: 278, loss: 1.2025428357124328\n",
      "epoch: 279, loss: 1.2008754312992096\n",
      "epoch: 280, loss: 1.1976714552640915\n",
      "epoch: 281, loss: 1.19570290851593\n",
      "epoch: 282, loss: 1.1941038259267807\n",
      "epoch: 283, loss: 1.1945180336236954\n",
      "epoch: 284, loss: 1.1905193507671357\n",
      "epoch: 285, loss: 1.188168436050415\n",
      "epoch: 286, loss: 1.186977203130722\n",
      "epoch: 287, loss: 1.1845492355823517\n",
      "epoch: 288, loss: 1.1832369319200515\n",
      "epoch: 289, loss: 1.1800446840524674\n",
      "epoch: 290, loss: 1.1777319172620773\n",
      "epoch: 291, loss: 1.1751824264526367\n",
      "epoch: 292, loss: 1.174511117219925\n",
      "epoch: 293, loss: 1.1735101904869079\n",
      "epoch: 294, loss: 1.1680651499032975\n",
      "epoch: 295, loss: 1.1690705490112305\n",
      "epoch: 296, loss: 1.168175935268402\n",
      "epoch: 297, loss: 1.165713345527649\n",
      "epoch: 298, loss: 1.1646697919368745\n",
      "epoch: 299, loss: 1.1616094448566436\n",
      "epoch: 300, loss: 1.1584733530282973\n",
      "epoch: 301, loss: 1.1563791289329528\n",
      "epoch: 302, loss: 1.1566333557367325\n",
      "epoch: 303, loss: 1.155895216345787\n",
      "epoch: 304, loss: 1.1509248756170274\n",
      "epoch: 305, loss: 1.1510302954912186\n",
      "epoch: 306, loss: 1.1470100866556168\n",
      "epoch: 307, loss: 1.1437819659709931\n",
      "epoch: 308, loss: 1.1439877316951752\n",
      "epoch: 309, loss: 1.1446972434520721\n",
      "epoch: 310, loss: 1.1393242931365968\n",
      "epoch: 311, loss: 1.1398595527410507\n",
      "epoch: 312, loss: 1.1359873803853988\n",
      "epoch: 313, loss: 1.1335772156715394\n",
      "epoch: 314, loss: 1.13441617500782\n",
      "epoch: 315, loss: 1.1316852587461472\n",
      "epoch: 316, loss: 1.1301795939207078\n",
      "epoch: 317, loss: 1.1317295798063278\n",
      "epoch: 318, loss: 1.1265129317045213\n",
      "epoch: 319, loss: 1.1243751491308211\n",
      "epoch: 320, loss: 1.1213558694124222\n",
      "epoch: 321, loss: 1.1219705069065093\n",
      "epoch: 322, loss: 1.1147276029586792\n",
      "epoch: 323, loss: 1.1159835973978043\n",
      "epoch: 324, loss: 1.1202080427408219\n",
      "epoch: 325, loss: 1.1140460696220398\n",
      "epoch: 326, loss: 1.1107378805875778\n",
      "epoch: 327, loss: 1.1132582689523698\n",
      "epoch: 328, loss: 1.1112602988481521\n",
      "epoch: 329, loss: 1.106365703701973\n",
      "epoch: 330, loss: 1.1050291785001756\n",
      "epoch: 331, loss: 1.1015529421567918\n",
      "epoch: 332, loss: 1.1065874377489089\n",
      "epoch: 333, loss: 1.0993241653442383\n",
      "epoch: 334, loss: 1.0977267717123032\n",
      "epoch: 335, loss: 1.0945878244638443\n",
      "epoch: 336, loss: 1.0933280667066574\n",
      "epoch: 337, loss: 1.0912007427215575\n",
      "epoch: 338, loss: 1.091712109208107\n",
      "epoch: 339, loss: 1.0921886999607087\n",
      "epoch: 340, loss: 1.0878372761011124\n",
      "epoch: 341, loss: 1.085235207915306\n",
      "epoch: 342, loss: 1.0836781816482544\n",
      "epoch: 343, loss: 1.0847935346364974\n",
      "epoch: 344, loss: 1.0783093506097794\n",
      "epoch: 345, loss: 1.0825651684999467\n",
      "epoch: 346, loss: 1.0742000000476837\n",
      "epoch: 347, loss: 1.07650283908844\n",
      "epoch: 348, loss: 1.0733685429096222\n",
      "epoch: 349, loss: 1.0712674236297608\n",
      "epoch: 350, loss: 1.0704437854290008\n",
      "epoch: 351, loss: 1.068750031232834\n",
      "epoch: 352, loss: 1.0657519754171372\n",
      "epoch: 353, loss: 1.0663798141479492\n",
      "epoch: 354, loss: 1.0652748820781708\n",
      "epoch: 355, loss: 1.0626210417747497\n",
      "epoch: 356, loss: 1.0579146134853363\n",
      "epoch: 357, loss: 1.0559507672786712\n",
      "epoch: 358, loss: 1.0585051645040513\n",
      "epoch: 359, loss: 1.0582334415912629\n",
      "epoch: 360, loss: 1.0482745006084442\n",
      "epoch: 361, loss: 1.0518368176221848\n",
      "epoch: 362, loss: 1.0502208124399186\n",
      "epoch: 363, loss: 1.0473228882551193\n",
      "epoch: 364, loss: 1.0442327395677566\n",
      "epoch: 365, loss: 1.0478708040714264\n",
      "epoch: 366, loss: 1.0455273855924607\n",
      "epoch: 367, loss: 1.042077892780304\n",
      "epoch: 368, loss: 1.0402011008262635\n",
      "epoch: 369, loss: 1.0397861703634261\n",
      "epoch: 370, loss: 1.038749572277069\n",
      "epoch: 371, loss: 1.0376436907052993\n",
      "epoch: 372, loss: 1.0309365196228026\n",
      "epoch: 373, loss: 1.028089977502823\n",
      "epoch: 374, loss: 1.030798768043518\n",
      "epoch: 375, loss: 1.0303986946344375\n",
      "epoch: 376, loss: 1.025889027118683\n",
      "epoch: 377, loss: 1.0297188493013383\n",
      "epoch: 378, loss: 1.0237337188720703\n",
      "epoch: 379, loss: 1.024142355442047\n",
      "epoch: 380, loss: 1.0180955406427383\n",
      "epoch: 381, loss: 1.014751156449318\n",
      "epoch: 382, loss: 1.0169348915815353\n",
      "epoch: 383, loss: 1.0157818126678466\n",
      "epoch: 384, loss: 1.011728615283966\n",
      "epoch: 385, loss: 1.015152361035347\n",
      "epoch: 386, loss: 1.0082722158432007\n",
      "epoch: 387, loss: 1.0104291191101074\n",
      "epoch: 388, loss: 1.0055036828517914\n",
      "epoch: 389, loss: 1.0124282071590422\n",
      "epoch: 390, loss: 1.0093806573152542\n",
      "epoch: 391, loss: 0.9983369101285935\n",
      "epoch: 392, loss: 0.9984659818410874\n",
      "epoch: 393, loss: 0.9998901722431183\n",
      "epoch: 394, loss: 0.9971123946905136\n",
      "epoch: 395, loss: 0.9950623364448548\n",
      "epoch: 396, loss: 0.998175604224205\n",
      "epoch: 397, loss: 0.9880221625566482\n",
      "epoch: 398, loss: 0.9916316913366318\n",
      "epoch: 399, loss: 0.9926291131973266\n",
      "epoch: 400, loss: 0.9793315194845199\n",
      "epoch: 401, loss: 0.9808503090143204\n",
      "epoch: 402, loss: 0.982997146487236\n",
      "epoch: 403, loss: 0.9876429445743561\n",
      "epoch: 404, loss: 0.9783646250963212\n",
      "epoch: 405, loss: 0.980683539390564\n",
      "epoch: 406, loss: 0.9806375790834427\n",
      "epoch: 407, loss: 0.9848211945295334\n",
      "epoch: 408, loss: 0.9799223589897156\n",
      "epoch: 409, loss: 0.9720438469648361\n",
      "epoch: 410, loss: 0.9635591779947281\n",
      "epoch: 411, loss: 0.9649474450349808\n",
      "epoch: 412, loss: 0.9694290390014648\n",
      "epoch: 413, loss: 0.9679056096076966\n",
      "epoch: 414, loss: 0.9690051217079163\n",
      "epoch: 415, loss: 0.9578147486448289\n",
      "epoch: 416, loss: 0.9623402829170227\n",
      "epoch: 417, loss: 0.9587206867933273\n",
      "epoch: 418, loss: 0.961745368719101\n",
      "epoch: 419, loss: 0.9595812788009643\n",
      "epoch: 420, loss: 0.9553299504518509\n",
      "epoch: 421, loss: 0.9627905334234238\n",
      "epoch: 422, loss: 0.9505010122060775\n",
      "epoch: 423, loss: 0.9463479099273682\n",
      "epoch: 424, loss: 0.9514052159786225\n",
      "epoch: 425, loss: 0.9534680823087692\n",
      "epoch: 426, loss: 0.9471100844144821\n",
      "epoch: 427, loss: 0.9478227450847626\n",
      "epoch: 428, loss: 0.9442130950689316\n",
      "epoch: 429, loss: 0.9468031299114227\n",
      "epoch: 430, loss: 0.9377964866161347\n",
      "epoch: 431, loss: 0.9388792370557785\n",
      "epoch: 432, loss: 0.928898026227951\n",
      "epoch: 433, loss: 0.9350515360832214\n",
      "epoch: 434, loss: 0.9411032639741898\n",
      "epoch: 435, loss: 0.9297912513017654\n",
      "epoch: 436, loss: 0.9318252065181732\n",
      "epoch: 437, loss: 0.9259998391866684\n",
      "epoch: 438, loss: 0.9242405480146408\n",
      "epoch: 439, loss: 0.9331197468042374\n",
      "epoch: 440, loss: 0.9306773852109909\n",
      "epoch: 441, loss: 0.9225537942647934\n",
      "epoch: 442, loss: 0.9137369630336761\n",
      "epoch: 443, loss: 0.9236302710771561\n",
      "epoch: 444, loss: 0.921138535618782\n",
      "epoch: 445, loss: 0.9130980703830719\n",
      "epoch: 446, loss: 0.9128020492792129\n",
      "epoch: 447, loss: 0.9119944381713867\n",
      "epoch: 448, loss: 0.9101408784389495\n",
      "epoch: 449, loss: 0.9017996109724045\n",
      "epoch: 450, loss: 0.9084488466978073\n",
      "epoch: 451, loss: 0.9135093905925751\n",
      "epoch: 452, loss: 0.9091372314691544\n",
      "epoch: 453, loss: 0.9128942048549652\n",
      "epoch: 454, loss: 0.9045151064395904\n",
      "epoch: 455, loss: 0.9074039618968963\n",
      "epoch: 456, loss: 0.8997622344493866\n",
      "epoch: 457, loss: 0.8928311767578125\n",
      "epoch: 458, loss: 0.8876985139846801\n",
      "epoch: 459, loss: 0.9015061510801315\n",
      "epoch: 460, loss: 0.8913552820682525\n",
      "epoch: 461, loss: 0.8948368601799012\n",
      "epoch: 462, loss: 0.8936512027978897\n",
      "epoch: 463, loss: 0.8875431654453277\n",
      "epoch: 464, loss: 0.8920545860528946\n",
      "epoch: 465, loss: 0.8882926279306411\n",
      "epoch: 466, loss: 0.8836855512857437\n",
      "epoch: 467, loss: 0.8851750235557556\n",
      "epoch: 468, loss: 0.8775291351079941\n",
      "epoch: 469, loss: 0.8721329288482667\n",
      "epoch: 470, loss: 0.8714594708681107\n",
      "epoch: 471, loss: 0.8733061348199844\n",
      "epoch: 472, loss: 0.8725294628143311\n",
      "epoch: 473, loss: 0.8761404279470444\n",
      "epoch: 474, loss: 0.8696974172592163\n",
      "epoch: 475, loss: 0.8730301247835159\n",
      "epoch: 476, loss: 0.8736305930614472\n",
      "epoch: 477, loss: 0.863290783405304\n",
      "epoch: 478, loss: 0.8719627491235733\n",
      "epoch: 479, loss: 0.865969461798668\n",
      "epoch: 480, loss: 0.8634518897533416\n",
      "epoch: 481, loss: 0.8583881556987762\n",
      "epoch: 482, loss: 0.8636660066843033\n",
      "epoch: 483, loss: 0.8620437452793122\n",
      "epoch: 484, loss: 0.8571151078939437\n",
      "epoch: 485, loss: 0.8604970340728759\n",
      "epoch: 486, loss: 0.8514019774198532\n",
      "epoch: 487, loss: 0.8478868709802627\n",
      "epoch: 488, loss: 0.84955488717556\n",
      "epoch: 489, loss: 0.8534133064746857\n",
      "epoch: 490, loss: 0.8429760353565217\n",
      "epoch: 491, loss: 0.8389846657514572\n",
      "epoch: 492, loss: 0.8491261233091354\n",
      "epoch: 493, loss: 0.848542512178421\n",
      "epoch: 494, loss: 0.8420191698074341\n",
      "epoch: 495, loss: 0.837124593257904\n",
      "epoch: 496, loss: 0.8430900439023972\n",
      "epoch: 497, loss: 0.8353311665058136\n",
      "epoch: 498, loss: 0.832226447224617\n",
      "epoch: 499, loss: 0.8366818792819977\n",
      "CPU times: user 41min 38s, sys: 8.79 s, total: 41min 47s\n",
      "Wall time: 41min 39s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "num_epochs = 500 # 学習回数\n",
    "losses = [] # 損失関数格納用\n",
    "\n",
    "# 学習回数（num_epochs）分ループ\n",
    "for epoch in range(num_epochs):\n",
    "    running_loss = 0.0\n",
    "\n",
    "    # ミニバッチ学習用のループ（100枚 x 600セットなので 600回ループ）\n",
    "    for imgs, labels in train_dataloader:\n",
    "        imgs = imgs.view(num_batches, -1) # Tensorの形状変換\n",
    "        # 変換前：Tensor[(100, 1, 28, 28)]\n",
    "        # 変更後：Tensor[(100, 784)]\n",
    "        # (100,-1)と設定すると自動的に　1x28x28=784　の計算結果が自動的に挿入される\n",
    "        imgs = imgs.to(device) # 画像データをデバイス(CPU or GPU）に送る\n",
    "        labels = labels.to(device) # 正解ラベルのデータをデバイス(CPU or GPU）に送る\n",
    "\n",
    "        optimizer.zero_grad() # 勾配を初期化（リセット）\n",
    "        output = model(imgs) # 順伝播させて予測結果をoutputに代入\n",
    "\n",
    "        loss = criterion(output, labels) # 予測結果と正解ラベル\bからLossを計算\n",
    "        running_loss += loss.item() # Loss値を表示するために加算\n",
    "\n",
    "        pred = torch.argmax(output, dim=1) #　0-9 のうち、最も確信度が高い「数字」をpredに代入\n",
    "\n",
    "        loss.backward() # 逆伝播：勾配計算\n",
    "        optimizer.step() # パラメータの更新\n",
    "\n",
    "    running_loss /= len(train_dataloader) # ミニバッチのループ数で割合を算出\n",
    "    losses.append(running_loss)\n",
    "\n",
    "    print(\"epoch: {}, loss: {}\".format(epoch, running_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f34ec351fd0>]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(losses) # 誤差が減少していることを確認"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. 検証\n",
    "## (1) 検証データから100枚ピックアップして検証"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "正解数: 67 個\n",
      "正解率: 67.0 %\n"
     ]
    }
   ],
   "source": [
    "count = 0.0\n",
    "for i in range(len(labels)): # 100枚で検証\n",
    "    if labels[i] == pred[i]:\n",
    "        count += 1\n",
    "\n",
    "print('正解数: {} 個'.format(int(count)))\n",
    "print('正解率: {} %' .format(count/len(labels) * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (2) 検証データ全体＝10,000枚　で検証"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([8, 1, 4, 6, 2, 1, 9, 5, 0, 6, 2, 7, 9, 1, 2, 8, 6, 9, 3, 8, 3, 3, 7, 0,\n",
       "        0, 6, 8, 6, 7, 7, 0, 9, 1, 7, 0, 0, 8, 9, 3, 3, 6, 7, 9, 3, 2, 1, 1, 7,\n",
       "        0, 9, 2, 1, 1, 6, 2, 0, 3, 7, 6, 3, 4, 3, 3, 1, 1, 2, 9, 7, 5, 3, 2, 2,\n",
       "        6, 7, 5, 7, 7, 5, 2, 4, 4, 3, 4, 9, 2, 5, 5, 6, 3, 5, 6, 4, 8, 4, 2, 9,\n",
       "        9, 7, 9, 4])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# テストデータが入ってる test_dataloaderで精度チェック\n",
    "test_iter = iter(test_dataloader) # イテレータとは何者か　https://pouhon.net/python-iter/2067/\n",
    "imgs, labels = test_iter.next() # 先頭から1バッチずつ取り出せる\n",
    "labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 上記のとおり、(1)の100枚だけで検証した場合であっても、(2)の全体で検証した場合と結果とほぼ同じになる\n",
    "\n",
    "### モデルの検証方法については次回以降で学習"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 学習済みモデルを保存する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = model.state_dict()\n",
    "torch.save(params, 'Peso_model.prm')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 学習済みモデルを読み込む"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_load = torch.load('Peso_model.prm')\n",
    "model.load_state_dict(param_load)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([8, 1, 2, 6, 4, 9, 1, 5, 0, 6, 4, 7, 8, 8, 6, 8, 6, 9, 3, 8, 6, 7, 8, 9,\n",
       "        9, 6, 8, 6, 4, 7, 1, 0, 9, 2, 9, 0, 8, 9, 0, 5, 6, 4, 9, 5, 6, 1, 3, 7,\n",
       "        4, 1, 9, 0, 1, 6, 6, 0, 3, 7, 2, 7, 2, 6, 7, 9, 1, 2, 1, 7, 5, 3, 0, 3,\n",
       "        6, 4, 6, 7, 2, 1, 2, 2, 1, 3, 4, 9, 2, 5, 5, 6, 9, 5, 3, 2, 8, 2, 5, 9,\n",
       "        9, 7, 6, 3], device='cuda:0')"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imgs_tensor = imgs.view(100,-1).to(device)\n",
    "output = model(imgs_tensor)\n",
    "pred = torch.argmax(output, dim=1)\n",
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "正解数： 5324 個\n",
      "正解率： 53.24 %\n"
     ]
    }
   ],
   "source": [
    "test_acc = 0\n",
    "total = 0\n",
    "for images, labels in test_dataloader: # 10,000枚で検証\n",
    "    images, labels = images.view(num_batches, -1).to(device), labels.to(device)\n",
    "    outputs = model(images)\n",
    "    pred = torch.argmax(outputs, dim=1) \n",
    "    test_acc += (pred == labels).sum().item()\n",
    "    # 上2行と同じ処理　test_acc += (outputs.max(1)[1] == labels).sum().item()\n",
    "    total += labels.size(0)\n",
    "\n",
    "print('正解数： {} 個'.format(int(test_acc)))    \n",
    "print('正解率： {} %'.format(100 * test_acc / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "53.24"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = 0\n",
    "\n",
    "for imgs, labels in test_dataloader:\n",
    "    labels = labels.to(device)\n",
    "    imgs_gpu = imgs.view(num_batches, -1).to(device)\n",
    "    output = model(imgs_gpu)\n",
    "    pred = torch.argmax(output, dim=1)\n",
    "    s += sum(labels==pred)\n",
    "    \n",
    "int(s)/100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
